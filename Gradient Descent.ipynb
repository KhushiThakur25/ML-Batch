{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbc5a00-da6e-45ad-8645-46ef39b554c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data: y = 2x + 1\n",
    "X = np.array([1, 2, 3, 4, 5], dtype=np.float32)\n",
    "y = np.array([3, 5, 7, 9, 11], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae9b7c4-c238-468d-b4f9-359b15c2c7da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize parameters (weights and bias)\n",
    "m = 0.0  # slope (weight)\n",
    "b = 0.0  # intercept (bias)\n",
    "learning_rate = 0.01\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7ea765-bb5d-4751-a648-eb681a68bace",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 57.0000, m = 0.5000, b = 0.1400\n",
      "Epoch 100: Loss = 0.0159, m = 2.0815, b = 0.7058\n",
      "Epoch 200: Loss = 0.0081, m = 2.0581, b = 0.7903\n",
      "Epoch 300: Loss = 0.0041, m = 2.0414, b = 0.8505\n",
      "Epoch 400: Loss = 0.0021, m = 2.0295, b = 0.8935\n",
      "Epoch 500: Loss = 0.0011, m = 2.0210, b = 0.9241\n",
      "Epoch 600: Loss = 0.0005, m = 2.0150, b = 0.9459\n",
      "Epoch 700: Loss = 0.0003, m = 2.0107, b = 0.9614\n",
      "Epoch 800: Loss = 0.0001, m = 2.0076, b = 0.9725\n",
      "Epoch 900: Loss = 0.0001, m = 2.0054, b = 0.9804\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent loop\n",
    "for epoch in range(epochs):\n",
    "    # Predicted value\n",
    "    y_pred = m * X + b\n",
    "    \n",
    "    # Compute gradients\n",
    "    D_m = (-2 / len(X)) * sum(X * (y - y_pred))\n",
    "    D_b = (-2 / len(X)) * sum(y - y_pred)\n",
    "    \n",
    "    # Update parameters\n",
    "    m -= learning_rate * D_m\n",
    "    b -= learning_rate * D_b\n",
    "    \n",
    "    # Print loss (optional)\n",
    "    if epoch % 100 == 0:\n",
    "        loss = sum((y - y_pred) ** 2) / len(X)\n",
    "        print(f\"Epoch {epoch}: Loss = {loss:.4f}, m = {m:.4f}, b = {b:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0790f4e-5e70-4192-8de8-298d248fe493",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model: y = 2.0039x + 0.9860\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFinal model: y = {m:.4f}x + {b:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc8d19a-514b-4b79-9a3c-94b88e175556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the function and its derivative\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "def df(x):\n",
    "    return 2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e150f7-09ca-4aad-a123-a4602f5ab68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: x = 8.0000, f(x) = 64.0000\n",
      "Epoch 10: x = 0.8590, f(x) = 0.7379\n",
      "Epoch 20: x = 0.0922, f(x) = 0.0085\n",
      "Epoch 30: x = 0.0099, f(x) = 0.0001\n",
      "Epoch 40: x = 0.0011, f(x) = 0.0000\n",
      "Epoch 50: x = 0.0001, f(x) = 0.0000\n",
      "Epoch 60: x = 0.0000, f(x) = 0.0000\n",
      "Epoch 70: x = 0.0000, f(x) = 0.0000\n",
      "Epoch 80: x = 0.0000, f(x) = 0.0000\n",
      "Epoch 90: x = 0.0000, f(x) = 0.0000\n",
      "\n",
      "Minimum value found at x = 0.0000, f(x) = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Initial guess\n",
    "x = 10.0  # Starting point (initial guess)\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "# Gradient descent loop\n",
    "for epoch in range(epochs):\n",
    "    # Compute the gradient at the current x\n",
    "    gradient = df(x)\n",
    "    \n",
    "    # Update x by taking a step in the opposite direction of the gradient\n",
    "    x -= learning_rate * gradient\n",
    "    \n",
    "    # Print the function value (optional)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: x = {x:.4f}, f(x) = {f(x):.4f}\")\n",
    "\n",
    "print(f\"\\nMinimum value found at x = {x:.4f}, f(x) = {f(x):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e6c85-b616-4c16-ace1-5236ad9ab213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
